{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Week 5 - Residual Connections and Layer Normalization",
   "id": "64617d898affbed4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Introduction & Objectives\n",
    "\n",
    "This notebook focuses on improving a neural network by incorporating advanced techniques, specifically residual connections and layer normalization. These enhancements are widely used in modern deep learning architectures to improve performance and stability. The primary objectives of this notebook are:\n",
    "\n",
    "1. Understand the concept and implementation of residual connections in neural networks.\n",
    "2. Learn how to effectively integrate layer normalization into a neural network model.\n"
   ],
   "id": "8f7b28955d450179"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Data Understanding\n",
    "\n",
    "In this notebook, we will use the [IMDB movie reviews dataset](https://keras.io/api/datasets/imdb/), a widely recognized benchmark for binary sentiment classification. The dataset consists of 50,000 reviews, evenly split into 25,000 for training and 25,000 for testing. Each review is labeled as either positive (1) or negative (0), making it ideal for binary classification tasks.\n",
    "\n",
    "The reviews have been preprocessed and are represented as lists of word indexes (integers). Words are indexed based on their overall frequency in the dataset, where, for example, the integer \"3\" represents the third most frequent word. This indexing system enables efficient filtering, such as limiting the vocabulary to the top 10,000 most frequent words while excluding overly common words, like the top 20."
   ],
   "id": "372434ac540a7c0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.1 Importing Libraries and Loading the Data\n",
    "\n",
    "We begin by importing the necessary libraries and loading the IMDB movie reviews dataset using the Keras API. The dataset is preprocessed and tokenized, allowing us to focus on model development and training."
   ],
   "id": "97f0e164479206e7"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-26T15:12:31.902503Z",
     "start_time": "2024-11-26T15:12:27.605051Z"
    }
   },
   "source": [
    "# Importing Libraries\n",
    "from keras.api.datasets import imdb\n",
    "from keras.api.preprocessing.sequence import pad_sequences\n",
    "from keras.src.layers import Input, Embedding, Attention, Add, LayerNormalization, Dense, Dropout, \\\n",
    "    GlobalAveragePooling1D\n",
    "from keras.src.models.model import Model"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 17:12:28.620274: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-26 17:12:28.726017: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-26 17:12:28.755969: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-26 17:12:28.946172: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-26 17:12:30.266258: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, we will load the IMDB movie reviews dataset and explore its structure and content.",
   "id": "93aa8609f33711a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T15:12:36.908057Z",
     "start_time": "2024-11-26T15:12:31.910821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_features = 10000  # Number of most frequent words to consider\n",
    "maxlen = 200  # Maximum length of sequences\n",
    "\n",
    "# Load the IMDB dataset\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ],
   "id": "41df1fbeacf1f895",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001B[1m17464789/17464789\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 0us/step\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The data is successfully loaded and preprocessed, ready for use in training and evaluation. We can now proceed to the next steps of building and enhancing our neural network model.",
   "id": "e75f19ead69c7bab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Building the Model\n",
    "\n",
    "In this section, we will construct a neural network model for sentiment classification using the IMDB movie reviews dataset. The model will incorporate residual connections and layer normalization to improve performance and stability."
   ],
   "id": "40c26ab65c728003"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T15:12:38.931251Z",
     "start_time": "2024-11-26T15:12:37.015187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build the model with residual connections and layer normalization\n",
    "inputs = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(max_features, 128)(inputs)\n",
    "\n",
    "# Attention layer\n",
    "attention_output = Attention()([embedding_layer, embedding_layer])\n",
    "\n",
    "# Residual connection around attention layer\n",
    "residual_attention_output = Add()([embedding_layer, attention_output])\n",
    "\n",
    "# Layer normalization after attention layer\n",
    "normalized_output = LayerNormalization()(residual_attention_output)\n",
    "\n",
    "# Dense layers for binary classification\n",
    "x = GlobalAveragePooling1D()(normalized_output)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ],
   "id": "be61ade81620c812",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732633957.454238    4944 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1732633957.647732    4944 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1732633957.647790    4944 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1732633957.652934    4944 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1732633957.652989    4944 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1732633957.653018    4944 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1732633957.906351    4944 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1732633957.906410    4944 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 17:12:37.906420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1732633957.906477    4944 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 17:12:37.906872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5529 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:09:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m200\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m200\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │  \u001B[38;5;34m1,280,000\u001B[0m │ input_layer[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "│ (\u001B[38;5;33mEmbedding\u001B[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m200\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ embedding[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],  │\n",
       "│ (\u001B[38;5;33mAttention\u001B[0m)         │                   │            │ embedding[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001B[38;5;33mAdd\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m200\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ embedding[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],  │\n",
       "│                     │                   │            │ attention[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m200\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │        \u001B[38;5;34m256\u001B[0m │ add[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n",
       "│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ layer_normalizat… │\n",
       "│ (\u001B[38;5;33mGlobalAveragePool…\u001B[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │      \u001B[38;5;34m8,256\u001B[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ dense[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │         \u001B[38;5;34m65\u001B[0m │ dropout[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,288,577\u001B[0m (4.92 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,288,577</span> (4.92 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,288,577\u001B[0m (4.92 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,288,577</span> (4.92 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The model has been created successfully, incorporating residual connections and layer normalization for improved performance. The next step is to compile and train the model on the IMDB movie reviews dataset.",
   "id": "90fb5fa6b0de8a6b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. Compiling and Fitting the Model\n",
    "\n",
    "In this section, we will compile and train the neural network model on the IMDB movie reviews dataset. We will use binary cross-entropy as the loss function and the Adam optimizer for training."
   ],
   "id": "64d2c6bf4cd0fd9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T15:12:49.804572Z",
     "start_time": "2024-11-26T15:12:38.985096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ],
   "id": "35211e7d3ef40efd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732633959.883394    5019 service.cc:146] XLA service 0x7f9bac0071e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732633959.883453    5019 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Ti, Compute Capability 8.9\n",
      "2024-11-26 17:12:39.923510: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-26 17:12:40.090602: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-11-26 17:12:41.107962: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1036', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m 99/625\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.5503 - loss: 0.6928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732633962.480465    5019 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 4ms/step - accuracy: 0.6941 - loss: 0.5533 - val_accuracy: 0.8662 - val_loss: 0.3254\n",
      "Epoch 2/5\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.8883 - loss: 0.2755 - val_accuracy: 0.8684 - val_loss: 0.3101\n",
      "Epoch 3/5\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9245 - loss: 0.1863 - val_accuracy: 0.8636 - val_loss: 0.3541\n",
      "Epoch 4/5\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9538 - loss: 0.1277 - val_accuracy: 0.8586 - val_loss: 0.3809\n",
      "Epoch 5/5\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9650 - loss: 0.0987 - val_accuracy: 0.8716 - val_loss: 0.4270\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The model has been successfully compiled and trained on the training data. We have also stored the training history to analyze the model's performance over time. The next step is to evaluate the model on the test set to assess its effectiveness in sentiment classification.",
   "id": "2d93bb4073fa95dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5. Evaluating the Model\n",
    "\n",
    "Finally, we will evaluate the performance of the neural network model on the test set of the IMDB movie reviews dataset. We will calculate the accuracy and loss metrics to assess the model's effectiveness in sentiment classification."
   ],
   "id": "fe30c9f0289c94df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T15:12:50.962984Z",
     "start_time": "2024-11-26T15:12:49.815503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy * 100:.2f}%')"
   ],
   "id": "229e4faec4f0af99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.8614 - loss: 0.4606\n",
      "Test Loss: 0.4673, Test Accuracy: 85.75%\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The model achieved a Test Accuracy of **85.75%** and a Test Loss of **0.4673**, indicating that it performs well on the sentiment classification task. The incorporation of residual connections and layer normalization has helped improve the model's performance and stability.",
   "id": "cbdbbfa43cc67ad8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6. Conclusion\n",
    "\n",
    "In this notebook, we successfully implemented a neural network model for sentiment classification using the IMDB movie reviews dataset. By incorporating residual connections and layer normalization, we enhanced the model's performance and stability, achieving a Test Accuracy of **85.75%**. These advanced techniques are widely used in modern deep learning architectures to improve training efficiency and model effectiveness."
   ],
   "id": "68d64b6b3b25913e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
